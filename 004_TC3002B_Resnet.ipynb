{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3119,"status":"ok","timestamp":1713819572638,"user":{"displayName":"Luis Guillermo Hern치ndez Rojas","userId":"02886710968836417946"},"user_tz":360},"id":"3oNlT3Jg0ygY"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","from matplotlib import pyplot as plt\n","import math\n","\n","# Choosing which GPU this notebook can access\n","# (useful when running multiple experiments in parallel, on different GPUs):\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n","\n","# Some hyper-parameters:\n","input_shape = [224, 224, 3] # We will resize the input images to this shape\n","batch_size  = 32            # Images per batch (reduce/increase according to the machine's capability)\n","num_epochs  = 300           # Max number of training epochs\n","random_seed = 42            # Seed for some random operations, for reproducibility"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1713819575147,"user":{"displayName":"Luis Guillermo Hern치ndez Rojas","userId":"02886710968836417946"},"user_tz":360},"id":"Q9boO4iy7yti","outputId":"bd32a596-fe97-4768-8de1-ad69fe02f120"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/TC3002B_CV\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/TC3002B_CV/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1713819578375,"user":{"displayName":"Luis Guillermo Hern치ndez Rojas","userId":"02886710968836417946"},"user_tz":360},"id":"nTbXoabp3NmY","outputId":"d3154e6c-cb7c-4dca-a03b-323f6bb0ac82"},"outputs":[{"output_type":"stream","name":"stdout","text":["tfds.core.DatasetInfo(\n","    name='cifar100',\n","    full_name='cifar100/3.0.2',\n","    description=\"\"\"\n","    This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n","    \"\"\",\n","    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n","    data_dir='/root/tensorflow_datasets/cifar100/3.0.2',\n","    file_format=tfrecord,\n","    download_size=160.71 MiB,\n","    dataset_size=132.03 MiB,\n","    features=FeaturesDict({\n","        'coarse_label': ClassLabel(shape=(), dtype=int64, num_classes=20),\n","        'id': Text(shape=(), dtype=string),\n","        'image': Image(shape=(32, 32, 3), dtype=uint8),\n","        'label': ClassLabel(shape=(), dtype=int64, num_classes=100),\n","    }),\n","    supervised_keys=('image', 'label'),\n","    disable_shuffling=False,\n","    splits={\n","        'test': <SplitInfo num_examples=10000, num_shards=1>,\n","        'train': <SplitInfo num_examples=50000, num_shards=1>,\n","    },\n","    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n","        author = {Alex Krizhevsky},\n","        title = {Learning multiple layers of features from tiny images},\n","        institution = {},\n","        year = {2009}\n","    }\"\"\",\n",")\n"]}],"source":["import cifar_utils\n","\n","cifar_info = cifar_utils.get_info()\n","print(cifar_info)\n","\n","# Number of classes:\n","num_classes = cifar_info.features['label'].num_classes\n","\n","# Number of images:\n","num_train_imgs = cifar_info.splits['train'].num_examples\n","num_val_imgs = cifar_info.splits['test'].num_examples\n","\n","train_steps_per_epoch = math.ceil(num_train_imgs / batch_size)\n","val_steps_per_epoch   = math.ceil(num_val_imgs / batch_size)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2834,"status":"ok","timestamp":1713819586473,"user":{"displayName":"Luis Guillermo Hern치ndez Rojas","userId":"02886710968836417946"},"user_tz":360},"id":"mEsphZZP8V4w"},"outputs":[],"source":["train_cifar_dataset = cifar_utils.get_dataset(\n","    phase='train', batch_size=batch_size, num_epochs=num_epochs, shuffle=True,\n","    input_shape=input_shape, seed=random_seed)\n","\n","val_cifar_dataset = cifar_utils.get_dataset(\n","    phase='test', batch_size=batch_size, num_epochs=1, shuffle=False,\n","    input_shape=input_shape, seed=random_seed)"]},{"cell_type":"markdown","metadata":{"id":"VS5TzIga8cFz"},"source":["Reusing ResNet-50 from Keras Apps\n","we will instantiate a ResNet-50 model, with **randomly-initialized parameters**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-TyMun88dxU"},"outputs":[],"source":["resnet50 = tf.keras.applications.resnet50.ResNet50(\n","    include_top=True, weights=None,\n","    input_shape=input_shape, classes=num_classes)\n","resnet50.summary()"]},{"cell_type":"markdown","metadata":{"id":"3k3acHgo9Bvk"},"source":["Training the Network\n","Once instantiated, our model from Keras Applications is like any ohter Keras model. Exactly as we did previously, we will train it on CIFAR:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZgdlxplT9FL2"},"outputs":[],"source":["import collections\n","import functools\n","from keras_custom_callbacks import SimpleLogCallback\n","\n","# Defining a custom metrics (top-5 accuracy), from a more generic one provided by Keras:\n","accuracy_metric = tf.metrics.SparseCategoricalAccuracy(name='acc')\n","top5_accuracy_metric = tf.metrics.SparseTopKCategoricalAccuracy(k=5, name='top5_acc')\n","\n","metrics_to_print = collections.OrderedDict([(\"loss\", \"loss\"),\n","                                            (\"v-loss\", \"val_loss\"),\n","                                            (\"acc\", \"acc\"),\n","                                            (\"v-acc\", \"val_acc\"),\n","                                            (\"top5-acc\", \"top5_acc\"),\n","                                            (\"v-top5-acc\", \"val_top5_acc\")])\n","\n","# Defining optimizer and callbacks for the training:\n","optimizer = tf.keras.optimizers.Adam()\n","\n","model_dir = './models/resnet_keras_app'\n","callbacks = [\n","    # Callback to interrupt the training if the validation loss/metrics stops improving for some epochs:\n","    tf.keras.callbacks.EarlyStopping(patience=8, monitor='val_acc',\n","                                     restore_best_weights=True),\n","    # Callback to log the graph, losses and metrics into TensorBoard:\n","    tf.keras.callbacks.TensorBoard(log_dir=model_dir, histogram_freq=0, write_graph=True),\n","    # Callback to save the model, e.g., every 5 epochs:\n","    tf.keras.callbacks.ModelCheckpoint(\n","        os.path.join(model_dir, 'weights-epoch{epoch:02d}-loss{val_loss:.2f}.h5'), period=5),\n","    # Callback to simply log metrics at the end of each epoch (saving space compared to verbose=1/2):\n","    SimpleLogCallback(metrics_to_print, num_epochs=num_epochs, log_frequency=1)\n","]\n","\n","# Finally, compiling and training:\n","resnet50.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n","                 metrics=[accuracy_metric, top5_accuracy_metric])\n","\n","history = resnet50.fit(train_cifar_dataset,  epochs=num_epochs, steps_per_epoch=train_steps_per_epoch,\n","                       validation_data=val_cifar_dataset, validation_steps=val_steps_per_epoch,\n","                       verbose=1, callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-x9A0II-Kaj"},"outputs":[],"source":["fig, ax = plt.subplots(3, 2, figsize=(15,10), sharex='col')\n","ax[0, 0].set_title(\"loss\")\n","ax[0, 1].set_title(\"val-loss\")\n","ax[1, 0].set_title(\"acc\")\n","ax[1, 1].set_title(\"val-acc\")\n","ax[2, 0].set_title(\"top5-acc\")\n","ax[2, 1].set_title(\"val-top5-acc\")\n","\n","ax[0, 0].plot(history.history['loss'])\n","ax[0, 1].plot(history.history['val_loss'])\n","ax[1, 0].plot(history.history['acc'])\n","ax[1, 1].plot(history.history['val_acc'])\n","ax[2, 0].plot(history.history['top5_acc'])\n","ax[2, 1].plot(history.history['val_top5_acc'])"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs9ic/PfEde3X9UNCJXAty"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}