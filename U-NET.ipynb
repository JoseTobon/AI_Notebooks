{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseTobon/AI_Notebooks/blob/main/U-NET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Architecture\n",
        "\n",
        "José Angel Tobón Salazar A01411655\n",
        "\n",
        "From https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/"
      ],
      "metadata": {
        "id": "zL1V-Lk9SYQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wyuB_W6lSSSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "\n",
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "metadata": {
        "id": "6-bmm6g2TnC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para redimensionar la imagen y la máscara a un tamaño específico (128, 128)\n",
        "\n",
        "def resize(input_image, input_mask):\n",
        "   input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "   input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "\n",
        "   return input_image, input_mask"
      ],
      "metadata": {
        "id": "Anxl_ZgNTrpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para aumentar el conjunto de datos. Si un número aleatorio es mayor a 0.5, la imagen y la máscara se voltean horizontalmente\n",
        "def augment(input_image, input_mask):\n",
        "   if tf.random.uniform(()) > 0.5:\n",
        "       input_image = tf.image.flip_left_right(input_image)\n",
        "       input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "   return input_image, input_mask"
      ],
      "metadata": {
        "id": "zmNuMvbqTwDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar la imagen y la máscara. La imagen se divide por 255 para que sus valores estén en el rango [0, 1]. A la máscara se le resta 1.\n",
        "def normalize(input_image, input_mask):\n",
        "   input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "   input_mask -= 1\n",
        "   return input_image, input_mask"
      ],
      "metadata": {
        "id": "hL19FdEgT1Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones para cargar y preprocesar las imágenes de entrenamiento y prueba. Primero se redimensionan, luego se aumentan (solo para las de entrenamiento) y finalmente se normalizan.\n",
        "\n",
        "def load_image_train(datapoint):\n",
        "   input_image = datapoint[\"image\"]\n",
        "   input_mask = datapoint[\"segmentation_mask\"]\n",
        "   input_image, input_mask = resize(input_image, input_mask)\n",
        "   input_image, input_mask = augment(input_image, input_mask)\n",
        "   input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "   return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "   input_image = datapoint[\"image\"]\n",
        "   input_mask = datapoint[\"segmentation_mask\"]\n",
        "   input_image, input_mask = resize(input_image, input_mask)\n",
        "   input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "   return input_image, input_mask"
      ],
      "metadata": {
        "id": "NHbOxW23T5fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación del pipeline de entrada. Se mapean las funciones de carga y preprocesamiento a los conjuntos de datos de entrenamiento y prueba.\n",
        "\n",
        "train_dataset = dataset[\"train\"].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = dataset[\"test\"].map(load_image_test, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "hlmsK2g_UCIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de los lotes (batches). Se definen los tamaños de los lotes y se crean los lotes para los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = test_dataset.take(3000).batch(BATCH_SIZE)\n",
        "test_batches = test_dataset.skip(3000).take(669).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "fa6PMUc2UGd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para visualizar una lista de imágenes. Se utiliza para visualizar la imagen de entrada, la máscara verdadera y la máscara predicha.\n",
        "\n",
        "def display(display_list):\n",
        " plt.figure(figsize=(15, 15))\n",
        "\n",
        " title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "\n",
        " for i in range(len(display_list)):\n",
        "   plt.subplot(1, len(display_list), i+1)\n",
        "   plt.title(title[i])\n",
        "   plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "   plt.axis(\"off\")\n",
        " plt.show()\n",
        "\n",
        "# Selecciona una imagen y una máscara aleatorias del conjunto de entrenamiento y las visualiza\n",
        "\n",
        "sample_batch = next(iter(train_batches))\n",
        "random_index = np.random.choice(sample_batch[0].shape[0])\n",
        "sample_image, sample_mask = sample_batch[0][random_index], sample_batch[1][random_index]\n",
        "display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "wPIc-G2DUMqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Architecture"
      ],
      "metadata": {
        "id": "DZfSPQWAUm_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Definición de las operaciones fundamentales de un modelo U-Net: una operación de convolución doble, una operación de muestreo descendente y una operación de muestreo ascendente. Estas operaciones se utilizan para construir la arquitectura completa del U-Net, que consta de una parte de contracción (que reduce la resolución espacial de la entrada y aumenta su profundidad) y una parte de expansión (que aumenta la resolución espacial de la entrada y reduce su profundidad), con una capa de cuello de botella entre ambas."
      ],
      "metadata": {
        "id": "9e7XaBQmojUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para realizar dos convoluciones seguidas. Se utiliza en varias partes de la U-Net.\n",
        "\n",
        "'''\n",
        "Define una función llamada double_conv_block que realiza dos operaciones de convolución 2D seguidas. En cada operación de convolución, se aplica un filtro\n",
        "(o kernel) a la entrada x. Este filtro tiene un tamaño de 3x3, se aplica con un relleno (‘padding’) de tipo ‘same’ (lo que significa que se añade un relleno a\n",
        "la entrada para que la salida tenga el mismo tamaño que la entrada), se utiliza una función de activación ReLU (Rectified Linear Unit) para introducir no linealidades\n",
        "en el modelo, y se inicializa con el inicializador ‘he_normal’ (que es una forma de inicialización de pesos recomendada para redes neuronales profundas). El número de\n",
        "filtros en cada operación de convolución es n_filters. Después de aplicar las dos convoluciones, la función devuelve la salida.\n",
        "'''\n",
        "\n",
        "def double_conv_block(x, n_filters):\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x"
      ],
      "metadata": {
        "id": "zHbf5nvIUf_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para realizar una convolución seguida de un MaxPooling. Se utiliza en la parte de contracción de la U-Net.\n",
        "\n",
        "'''\n",
        "Definición de función llamada downsample_block que realiza una operación de muestreo descendente (downsampling). Primero, se aplica la función double_conv_block a la\n",
        "entrada x para realizar dos convoluciones 2D. Luego, se aplica una operación de MaxPooling con un tamaño de pool de 2x2 para reducir la resolución espacial de la entrada\n",
        "(es decir, para reducir su altura y anchura). Finalmente, se aplica una operación de Dropout con una tasa de 0.3 para prevenir el sobreajuste durante el entrenamiento.\n",
        "La función devuelve tanto la salida de la operación de convolución (f) como la salida de la operación de Dropout (p).\n",
        "'''\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "\n",
        "   return f, p"
      ],
      "metadata": {
        "id": "VeuGQU2ZU1mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para realizar una transposición de convolución seguida de una concatenación. Se utiliza en la parte de expansión de la U-Net.\n",
        "\n",
        "'''\n",
        "Definición de función llamada upsample_block que realiza una operación de muestreo ascendente (upsampling). Primero, se aplica una operación de transposición de convolución\n",
        "2D a la entrada x para aumentar su resolución espacial (es decir, para aumentar su altura y anchura). Luego, se concatena la salida de esta operación con las características\n",
        "de convolución conv_features de la parte de contracción del U-Net. Después, se aplica una operación de Dropout con una tasa de 0.3 para prevenir el sobreajuste durante el\n",
        "entrenamiento. Finalmente, se aplica la función double_conv_block para realizar dos convoluciones 2D. La función devuelve la salida de estas convoluciones.\n",
        "'''\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenar\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "\n",
        "   return x"
      ],
      "metadata": {
        "id": "bwht9D7dU7C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net Model"
      ],
      "metadata": {
        "id": "G0DT532cVjAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para construir el modelo completo de la U-Net. Se definen las entradas, se construyen las partes de contracción y expansión y se definen las salidas.\n",
        "\n",
        "'''\n",
        "Se define la función build_unet_model que construye el modelo completo de la U-Net. Primero, se definen las entradas del modelo. Luego, se construye la parte de contracción\n",
        "del U-Net utilizando la función downsample_block definida anteriormente. Después de la contracción, se aplica una operación de convolución doble para crear el cuello de botella\n",
        "del U-Net. A continuación, se construye la parte de expansión del U-Net utilizando la función upsample_block definida anteriormente. Finalmente, se definen las salidas del modelo\n",
        "y se crea el modelo U-Net utilizando la API funcional de Keras.\n",
        "'''\n",
        "\n",
        "def build_unet_model():\n",
        "\n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(128,128,3))\n",
        "\n",
        "    # encoder: contracting path - downsample\n",
        "    # 1 - downsample\n",
        "    f1, p1 = downsample_block(inputs, 64)\n",
        "    # 2 - downsample\n",
        "    f2, p2 = downsample_block(p1, 128)\n",
        "    # 3 - downsample\n",
        "    f3, p3 = downsample_block(p2, 256)\n",
        "    # 4 - downsample\n",
        "    f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "    # 5 - bottleneck\n",
        "    bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "    # decoder: expanding path - upsample\n",
        "    # 6 - upsample\n",
        "    u6 = upsample_block(bottleneck, f4, 512)\n",
        "    # 7 - upsample\n",
        "    u7 = upsample_block(u6, f3, 256)\n",
        "    # 8 - upsample\n",
        "    u8 = upsample_block(u7, f2, 128)\n",
        "    # 9 - upsample\n",
        "    u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "    # outputs\n",
        "    outputs = layers.Conv2D(3, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "\n",
        "    # unet model with Keras Functional API\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "\n",
        "    return unet_model"
      ],
      "metadata": {
        "id": "vPW0QLRkVlE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación del modelo de la U-Net\n",
        "\n",
        "unet_model = build_unet_model()"
      ],
      "metadata": {
        "id": "Bq_-ziFpVopI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile and Train"
      ],
      "metadata": {
        "id": "Gt3W8OJJVsCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilación del modelo. Se define el optimizador, la función de pérdida y las métricas.\n",
        "\n",
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "OnmjH5-DVpR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo. Se define el número de épocas, los pasos por época y los pasos de validación.\n",
        "\n",
        "'''\n",
        "Se entrena el modelo U-Net. Primero, se definen varios parámetros para el entrenamiento, como el número de épocas, los pasos por época y los pasos de validación.\n",
        "Luego, se llama al método fit del modelo para entrenarlo con los lotes de entrenamiento. También se especifican los lotes de validación para evaluar el rendimiento\n",
        "del modelo después de cada época.\n",
        "'''\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "TRAIN_LENGTH = info.splits[\"train\"].num_examples\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 5\n",
        "TEST_LENTH = info.splits[\"test\"].num_examples\n",
        "VALIDATION_STEPS = TEST_LENTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "model_history = unet_model.fit(train_batches,\n",
        "                              epochs=NUM_EPOCHS,\n",
        "                              steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                              validation_steps=VALIDATION_STEPS,\n",
        "                              validation_data=test_batches)"
      ],
      "metadata": {
        "id": "ljN1P84kVw6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "3yUpD3N9V2BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones para crear la máscara de predicción y mostrar las predicciones. Se utilizan para visualizar las predicciones del modelo.\n",
        "\n",
        "'''\n",
        "Se definen dos funciones, create_mask y show_predictions, y luego cuenta el número de lotes en el conjunto de prueba. La función create_mask toma una máscara de predicción\n",
        "y devuelve la clase con la mayor probabilidad para cada píxel. La función show_predictions muestra las predicciones del modelo para una o más imágenes. Si se proporciona un\n",
        "conjunto de datos, muestra las predicciones para las primeras num imágenes de ese conjunto de datos. Si no se proporciona un conjunto de datos, muestra la predicción para una\n",
        "imagen de muestra.\n",
        "'''\n",
        "\n",
        "def create_mask(pred_mask):\n",
        " pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        " pred_mask = pred_mask[..., tf.newaxis]\n",
        " return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        " if dataset:\n",
        "   for image, mask in dataset.take(num):\n",
        "     pred_mask = unet_model.predict(image)\n",
        "     display([image[0], mask[0], create_mask(pred_mask)])\n",
        " else:\n",
        "   display([sample_image, sample_mask,\n",
        "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "\n",
        "# Cuenta el número de lotes en el conjunto de prueba\n",
        "count = 0\n",
        "for i in test_batches:\n",
        "   count +=1\n",
        "print(\"number of batches:\", count)"
      ],
      "metadata": {
        "id": "H1kADRGnVzGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra las predicciones del modelo para tres imágenes del conjunto de prueba\n",
        "\n",
        "show_predictions(test_batches.skip(5), 3)"
      ],
      "metadata": {
        "id": "DmMwBaAxXxaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}